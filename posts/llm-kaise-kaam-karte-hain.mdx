---
title: "LLM कैसे काम करते हैं? बिना मुश्किल गणित के समझिए"
slug: "llm-kaise-kaam-karte-hain"
date: 2025-01-28T10:00:00Z
excerpt: "Large Language Models (LLMs) कोई जादू नहीं हैं। वे सेल्फ-सुपरविजन, खास आर्किटेक्चर और ह्यूमन अलाइनमेंट के कॉम्बिनेशन से काम करते हैं। आइए इन कॉम्प्लेक्स सिस्टम्स को आसान भाषा में समझते हैं।"
tags:
  - "AI"
  - "LLM"
  - "Machine Learning"
  - "GPT"
  - "BERT"
  - "Technology"
category: "technical-analysis"
author: "Neelam"
heroImage: "/images/uploads/llm-kaise-kaam-karte-hain/hero-image.jpg"
heroImagePrompt: "JUST LEAVE THIS AS IT IS"
quiz:
  - q: "LLMs को ट्रेन करने के लिए सबसे असरदार स्ट्रैटेजी कौन सी है?"
    options: ["Unsupervised Learning", "Supervised Learning", "Self-supervised Learning"]
    answer: 2
  - q: "कौन सा आर्किटेक्चर टेक्स्ट जेनरेट करने (जैसे कहानी लिखना) के लिए सबसे अच्छा है?"
    options: ["Encoder-only (BERT)", "Decoder-only (GPT)", "Encoder-Decoder (T5)"]
    answer: 1
  - q: "RLHF का पूरा नाम क्या है और इसका इस्तेमाल क्यों किया जाता है?"
    options: ["Reinforcement Learning from Human Feedback, मॉडल को अलाइन करने के लिए", "Recursive Learning for Huge Files, डेटा प्रोसेस करने के लिए", "Rapid Learning with Human Fast-tracking, ट्रेनिंग तेज करने के लिए"]
    answer: 0
  - q: "जब एक मॉडल को किसी वाक्य में खाली छोड़े गए शब्दों को भरने के लिए ट्रेन किया जाता है, तो उसे क्या कहते हैं?"
    options: ["Causal Language Modeling", "Masked Language Modeling", "Text-to-Text Modeling"]
    answer: 1
---

{/*  Start of Hindi article body  */}

हाल ही में, 2025 की एक टेक्स्टबुक "Foundations of Large Language Models" ने इस बात पर से पर्दा उठाया है कि Large Language Models (LLMs) असल में कैसे काम करते हैं। कई लोगों को लगता है कि ये किसी जादू की तरह हैं, लेकिन सच्चाई इससे कहीं ज़्यादा दिलचस्प और इंजीनियरिंग का कमाल है।

अगर आप LLMs के पीछे की technology को बिना किसी मुश्किल गणित के समझना चाहते हैं, तो यह लेख आपके लिए है।

### सबसे पहली और ज़रूरी बात: Pre-training

LLMs को समझने के लिए, सबसे पहले ‘pre-training’ के कॉन्सेप्ट को जानना ज़रूरी है। पारंपरिक machine learning में, हम एक model को किसी एक काम के लिए लेबल किए गए data (जैसे, tweets को 'positive' या 'negative' में क्लासिफाई करना) पर ट्रेन करते हैं।

लेकिन LLMs के साथ, हम एक अलग तरीका अपनाते हैं। हम model को किसी एक काम के लिए ट्रेन करने के बजाय, उसे बिना लेबल वाले अरबों-खरबों शब्दों के text पर ट्रेन करते हैं। model को खुद ही भाषा के पैटर्न को "समझने" के लिए छोड़ दिया जाता है। इस प्रोसेस को **self-supervised learning** कहते हैं।

तीन मुख्य pre-training स्ट्रैटेजी हैं:
1.  **Unsupervised:** model बिना किसी लेबल के पैटर्न सीखते हैं।
2.  **Supervised:** model लेबल किए गए data से सीखते हैं।
3.  **Self-supervised:** model बिना लेबल वाले data से अपने खुद के लेबल बनाते हैं (जैसे, text में से कुछ शब्दों को छिपाकर उन्हें फिर से अनुमान लगाना)।

LLMs तीसरी और सबसे असरदार स्ट्रैटेजी का इस्तेमाल करते हैं।

### Self-supervised Learning काम कैसे करती है?

यह बहुत सरल आइडिया पर आधारित है। एक वाक्य लें:
“the early bird catches the worm.”

अब इसमें से कुछ शब्दों को छिपा दें (mask कर दें):
“the [MASK] bird catches the [MASK]”

अब model से इन खाली जगहों को भरने के लिए कहा जाता है। इसके लिए किसी बाहरी लेबल की ज़रूरत नहीं है; text खुद ही सुपरविज़न का काम करता है। model को सही शब्द ("early" और "worm") का अनुमान लगाने के लिए आस-पास के शब्दों के कॉन्टेक्स्ट का इस्तेमाल करना पड़ता है। लाखों-करोड़ों बार ऐसा करने से, model भाषा के ग्रामर, फैक्ट्स और यहाँ तक कि तर्क करने के पैटर्न को भी सीख जाता है।

![Masked Language Modeling का एक उदाहरण](/images/uploads/llm-kaise-kaam-karte-hain/masked-language-modeling.jpg)

### तीन मुख्य आर्किटेक्चर

इस pre-training के आइडिया से तीन मुख्य आर्किटेक्चर सामने आते हैं, और हर एक की अपनी ताकत है:

1.  **Encoder-only (जैसे BERT):** यह text को पढ़ने और समझने में माहिर है।
2.  **Decoder-only (जैसे GPT):** यह अगला शब्द जेनरेट करने में माहिर है।
3.  **Encoder-Decoder (जैसे T5, BART):** यह इनपुट पढ़ता है और फिर आउटपुट जेनरेट करता है।

आइए इन्हें थोड़ा और गहराई से देखें।

#### 1. Decoder-Only (GPT-स्टाइल)

इन्हें पिछले टोकन (शब्दों) के आधार पर अगले टोकन की भविष्यवाणी करने के लिए ट्रेन किया जाता है। उदाहरण के लिए:
`"the cat sat on the [MASK]"` → model भविष्यवाणी करेगा `"mat"`

इस प्रोसेस को **Causal Language Modeling** कहते हैं। यह एक दिशा में काम करता है—बाएं से दाएं। इसी वजह से GPT जैसे model टेक्स्ट जेनरेट करने, कहानी लिखने या सवालों के जवाब देने में इतने अच्छे होते हैं।

![Decoder-only आर्किटेक्चर का डायग्राम](/images/uploads/llm-kaise-kaam-karte-hain/decoder-only-architecture.jpg)

#### 2. Encoder-Only (BERT-स्टाइल)

यह आर्किटेक्चर एक बार में पूरे वाक्य को देखता है, कुछ शब्दों को रैंडमली मास्क करता है, और फिर उन्हें फिर से बनाने की कोशिश करता है। इसे **Masked Language Modeling** कहते हैं।

चूंकि यह मास्क किए गए शब्द के बाएं और दाएं, दोनों तरफ के कॉन्टेक्स्ट को देख सकता है, इसलिए यह भाषा की गहरी समझ विकसित करता है। यह इसे सेंटेंस क्लासिफिकेशन (जैसे sentiment analysis) या Named Entity Recognition जैसे कामों के लिए बेहतर बनाता है।

#### 3. Encoder-Decoder (T5-स्टाइल)

यह आर्किटेक्चर हर NLP टास्क को "टेक्स्ट-से-टेक्स्ट" समस्या के रूप में देखता है। आप इसे एक कमांड देते हैं, और यह आपको text के रूप में आउटपुट देता है।

उदाहरण:
-   `"translate English to German: hello"` → `"hallo"`
-   `"classify sentiment: i hate this"` → `"negative"`

एक ही model का इस्तेमाल ट्रांसलेशन, समराइजेशन (summarization), सवाल-जवाब आदि के लिए किया जा सकता है, जो इसे बहुत फ्लेक्सिबल बनाता है।

![Encoder-Decoder आर्किटेक्चर का डायग्राम](/images/uploads/llm-kaise-kaam-karte-hain/encoder-decoder-architecture.png)

### Pre-training के बाद क्या? Fine-tuning और Prompting

एक बार जब model को pre-train कर लिया जाता है, तो हमारे पास दो विकल्प होते हैं:

1.  **Fine-tune:** model को किसी खास काम के लिए लेबल किए गए data पर और ट्रेन करना।
2.  **Prompt:** model से अपनी इच्छानुसार काम करवाने के लिए स्मार्ट इनपुट (निर्देश) लिखना।

आजकल हम जिस "जादू" का अनुभव करते हैं, वह **prompting** की वजह से है। Prompting बस model को मनचाहा आउटपुट देने के लिए इनपुट को सावधानी से तैयार करने की कला है।

उदाहरण के लिए, यदि आप लिखते हैं:
`"i love this movie. sentiment:"`

तो model संभवतः इसे `"positive"` के साथ पूरा करेगा। यदि आप अपने इनपुट से पहले कुछ उदाहरण जोड़ते हैं, तो model उस पैटर्न को सीख लेता है। इसे **in-context learning** कहते हैं।

Prompting की दुनिया बहुत गहरी है और इसमें कई एडवांस्ड स्ट्रैटेजी शामिल हैं:
-   **Chain of Thought:** model को "कदम-दर-कदम सोचने" के लिए कहना।
-   **Problem Decomposition:** बड़ी समस्याओं को छोटे-छोटे हिस्सों में तोड़ना।
-   **Self-refinement:** model से अपने ही आउटपुट की आलोचना करने और उसे सुधारने के लिए कहना।
-   **RAG (Retrieval-Augmented Generation):** model को बाहरी सोर्स (जैसे internet) से जानकारी देखने की अनुमति देना।

![विभिन्न प्रॉम्प्टिंग रणनीतियों का एक उदाहरण](/images/uploads/llm-kaise-kaam-karte-hain/prompting-strategies.jpg)

### मॉडल को सुरक्षित बनाना: Human Alignment

LLMs को सिर्फ स्मार्ट बनाने के लिए ट्रेन नहीं किया जाता है - उन्हें इंसानी मूल्यों के साथ अलाइन (align) करना भी ज़रूरी है। यह कैसे किया जाता है?

-   **Supervised Fine-Tuning (SFT):** model को इंसानों द्वारा लिखे गए अच्छे जवाबों के उदाहरणों पर ट्रेन करना।
-   **RLHF (Reinforcement Learning from Human Feedback):** एक अलग "रिवॉर्ड मॉडल" को ट्रेन करना जो अच्छे आउटपुट को बुरे आउटपुट पर प्राथमिकता देना सीखता है। ChatGPT को इसी तरह अलाइन किया गया था।

अलाइनमेंट एक कठिन समस्या है। **Direct Preference Optimization (DPO)** जैसी नई विधियाँ RLHF की अस्थिरता से बचती हैं और अधिक लोकप्रिय हो रही हैं। लक्ष्य एक ही है: model को मददगार, हानिरहित और ईमानदार जवाबों की ओर गाइड करना।

### अंतिम चरण: कुशल Inference

इन विशाल मॉडलों को कुशलतापूर्वक चलाना भी एक चुनौती है। जब आप कोई प्रॉम्प्ट देते हैं, तो आपको तुरंत जवाब कैसे मिलता है? इसके पीछे कई ऑप्टिमाइज़ेशन तकनीकें हैं:
-   स्मार्ट डिकोडिंग (Top-k, Nucleus sampling) का इस्तेमाल करना।
-   पिछले परिणामों को कैश (cache) करना।
-   एक साथ कई अनुरोधों को बैच (batch) करना।
-   बेहतर मेमोरी और पोजिशन इंटरपोलेशन के साथ कॉन्टेक्स्ट को स्केल करना।

इन्हीं तकनीकों की वजह से हमें तेज़ और कम लेटेंसी वाले जवाब मिलते हैं।

### निष्कर्ष

संक्षेप में, LLMs इसलिए काम करते हैं क्योंकि वे:
1.  Self-supervision के माध्यम से विशाल text data से सीखते हैं।
2.  टोकन सीक्वेंस को मॉडल करने के लिए ट्रांसफॉर्मर आर्किटेक्चर का इस्तेमाल करते हैं।
3.  किसी भी काम के लिए प्रॉम्प्ट या फाइन-ट्यून किए जा सकते हैं।
4.  इंसानी प्राथमिकताओं के साथ अलाइन किए जाते हैं।
5.  तेज़ प्रतिक्रिया के लिए Inference पर ऑप्टिमाइज़ किए जाते हैं।

वे कोई जादू नहीं हैं, बल्कि जनरल-पर्पस टेक्स्ट रीजनिंग मशीनें हैं जो स्केल, स्मार्ट आर्किटेक्चर और सावधानीपूर्वक अलाइनमेंट का नतीजा हैं।

{/*  End of Hindi article body  */}

---